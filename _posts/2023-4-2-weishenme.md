---
layout: post
title: The Book of Why The New Science of Cause and Effect
categories: [Books, Technology]
tags: [technology]
---
#### 无知和傲慢——二者总是紧密结合在一起。
#### 人类获得知识的过程不是快乐的，而是痛苦的，伴随着叛逆、内疚和惩罚。
#### 图灵问道：“与其试图编写一个模拟成人思维的程序，何不尝试编写一个模拟儿童思维的程序？”如果能做到这一点，那么你就可以像教小孩子一样教它了。
#### P（S|T）P（T）=P（T|S）P（S）　 这个看似简单的方程就是贝叶斯法则。
#### 获得信息的方式和信息本身一样重要。
#### 近年来，人工智能最显著的进步发生在一个被称为“深度学习”的领域，它采用的基本方法类似于卷积神经网络。这些网络不遵循概率规则，它们不以严谨或清晰的方式处理不确定性，也没有对其运行环境的明确表征。相反，这些网络的体系结构可以自行发展。在完成了一个对于新的网络的训练后，程序员就不再管它，也无从知晓它正在执行什么计算，或者它们为何有效。如果网络失灵，程序员也不知道应该如何修复它。
<!-- more -->
每一门蒸蒸日上的科学都是在其符号系统的基础上繁荣发展起来的。 ——奥古斯都·德·摩根（1864）

人类获得知识的过程不是快乐的，而是痛苦的，伴随着叛逆、内疚和惩罚。

人类在进化早期就意识到世界并非由枯燥的事实（我们今天可能称之为数据）堆砌而成；相反，这些事实是通过错综复杂的因果关系网络融合在一起的。

没有哪台机器可以从原始数据中获得解释。对数据的解释需要借助外部推力。

除非你能想象出事情的结果，否则寻问事情的原因就是徒劳的。反过来说，你不能声称是夏娃导致你吃了树上的苹果，除非你可以想象一个世界，在那个世界里，情况与事实相反，她没有给你那个苹果。

但当我们想要让计算机来模拟人类思维，或者试图解决陌生的科学问题时，绘制一个清晰的由点和箭头组成的图示是非常有用的。

但当我们想要让计算机来模拟人类思维，或者试图解决陌生的科学问题时，绘制一个清晰的由点和箭头组成的图示是非常有用的。这些因果图就是我在导言中所描述的“因果推理引擎”的计算核心。

如果观察到某一事件改变了观察到另一事件的可能性，我们便说这一事件与另一事件相关联。

深度学习的成果确实举世瞩目、令人惊叹。然而，它的成功主要告诉我们的是之前我们认为困难的问题或任务实际上并不难，而并没有解决真正的难题，这些难题仍在阻碍着类人智能机器的实现。

公众误以为“强人工智能”（像人一样思考的机器）的问世指日可待，甚至可能已经到来，而事实远非如此。

人工智能领域“喷涌出大量的微发现”，这些发现也许是不错的新素材，但很遗憾，机器仍与类人认知相去甚远。

强人工智能这一目标是制造出拥有类人智能的机器，让它们能与人类交流并指导人类的探索方向。而深度学习只是让机器具备了高超的能力，而非智能。这种差异是巨大的，原因就在于后者缺少现实模型。

与30年前一样，当前的机器学习程序（包括那些应用深度神经网络的程序）几乎仍然完全是在关联模式下运行的。它们由一系列观察结果驱动，致力于拟合出一个函数，就像统计学家试图用点集拟合出一条直线一样。深度神经网络为拟合函数的复杂性增加了更多的层次，但其拟合过程仍然由原始数据驱动。被拟合的数据越来越多，拟合的精度不断提高，但该过程始终未能从我们先前提到的那种“超进化加速”中获益。

机器是不会自己弄明白手里拿着一瓶威士忌的行人可能对鸣笛做出的不同反应的。处于因果关系之梯最底层的任何运作系统都不可避免地缺乏这种灵活性和适应性。

预测干预结果的一种非常直接的方法是在严格控制的条件下进行实验。像脸书这样的大数据公司深知实验的力量，它们在实践中不断地进行各种实验，比如考察页面上的商品排序不同或者给用户设置不同的付款期限（甚至不同的价格）会导致用户行为发生怎样的改变。

一个足够强大的、准确的因果模型可以让我们利用第一层级（关联）的数据来回答第二层级（干预）的问题。没有因果模型，我们就不能从第一层级登上第二层级。这就是深度学习系统（只要它们只使用了第一层级的数据而没有利用因果模型）永远无法回答干预问题的原因，干预行动据其本意就是要打破机器训练的环境规则。

反事实与数据之间存在着一种特别棘手的关系，因为数据顾名思义就是事实。数据无法告诉我们在反事实或虚构的世界里会发生什么，在反事实世界里，观察到的事实被直截了当地否定了。然而，人类的思维却能可靠地、重复地进行这种寻求背后解释的推断。当夏娃把“蛇欺骗了我”作为她的行动理由时，她就是这么做的。这种能力彻底地区分了人类智能与动物智能，以及人类与模型盲版本的人工智能和机器学习。

从想象的反事实中，我们获得的独特优势是灵活性、反省能力和改善过去行为的能力，更重要的一点是对过去和现在的行为承担责任的意愿。古往今来，我们一直受益于反事实推理。

他写道：“我相信，在大约50年的时间里，高水准地完成模仿游戏的程序就会出现，普通询问者在5分钟的提问时间结束后正确识别对象是否为人的概率会低于70%。”

图灵坚信这个测试是可行的。他写道：“我相信，在大约50年的时间里，高水准地完成模仿游戏的程序就会出现，普通询问者在5分钟的提问时间结束后正确识别对象是否为人的概率会低于70%。”

但截至2015年，大赛已举办了25届，仍然没有一个程序能骗过所有裁判，甚至骗过哪怕一半的裁判。

图灵问道：“与其试图编写一个模拟成人思维的程序，何不尝试编写一个模拟儿童思维的程序？”如果能做到这一点，那么你就可以像教小孩子一样教它了。

儿童的大脑与我们从文具店购买的空白笔记本相差无几，”他写道，“预先设定的机制极少，有着大量的空白。”在这一点上，图灵错了：儿童的大脑有着丰富的预设机制和预存模板。 不过，我认为图灵还是说中了一部分事实。在创造出具备孩童智能水平的机器人之前，我们可能的确无法成功创造出类人智能，而创造出前者的关键要素就是掌握因果关系。

在让机器进行迷你图灵测试的准备阶段，表示问题必须优先于获取问题。如果缺少表示方法，我们就不知道如何存储信息以供将来使用。

1980年，哲学家约翰·塞尔以“中文屋”（Chinese Room）论证介绍了这种作弊的可能性，以此挑战图灵的说法——伪造智能的能力就相当于拥有智能。塞尔的质疑只有一个瑕疵：作弊并不容易——事实上，作弊根本就是不可能的。

如果我们希望计算机能理解因果关系，我们就必须教会它如何打破规则，让它懂得“观察到某事件”和“使某事件发生”之间的区别。我们需要告诉计算机：“无论何时，如果你想使某事发生，那就删除指向该事的所有箭头，之后继续根据逻辑规则进行分析，就好像那些箭头从未出现过一样。”

这个案例涉及欧洲首次引进天花疫苗所引发的大规模公开辩论。出人意料的是，数据显示有更多的人死于天花疫苗，而非死于天花。有些人理所当然地利用这些信息辩称，应该禁止人们接种疫苗，而不顾疫苗实际上根除了天花，挽救了许多生命的事实。

将反事实世界与现实世界进行比较，我们就可以得出真正的结论：

无论是在认知意义上还是在哲学意义上，因果观都比概率观更重要。

在理解语言和任何数学运算之前，我们就开始学习因果知识了。

从赖欣巴哈和萨普斯开始，哲学家们开始使用“概率提高”的概念来定义因果关系：如果X提高了Y的概率，那么我们就说X导致了Y。

这个概念也存在于我们的直觉中，并且根深蒂固。例如，当我们说“鲁莽驾驶会导致交通事故”或“你会因为懒惰而挂科”时，我们很清楚地知道，前者只是增加了后者发生的可能性，而非必然会让后者发生。鉴于此，人们便期望让概率提高准则充当因果关系之梯第一层级和第二层级之间的桥梁。然而，正是这种直觉导致了数十年失败的探索。

哲学家几乎无一例外地使用了条件概率来表示“X提高了Y的概率”，记作P（Y|X）>P（Y）。你肯定注意到了，这种解释是错的，因为“提高”是一个因果概念，意味着X对Y的因果效应，而公式P（Y|X）>P（Y）只涉及观察和手段，表示的是“如果我们观察到了X，那么Y的概率就提高了”。

任何试图用看似简单的第一层级的概念去“定义”因果关系的做法都必定会失败。

用类似表达式P（Y|X）所表示的概率位于因果关系之梯的第一层级，其不能（靠自己）回答第二层级或第三层级的问题。任何试图用看似简单的第一层级的概念去“定义”因果关系的做法都必定会失败。

如果我们从表面意义上采用概率提高准则，那么面对在冰激凌热销的月份里，犯罪的概率也提高了这一事实，我们就必然得出冰激凌的热销会导致犯罪的结论。在这个特例中，这一现象实际上可以解释为，因为夏天天气炎热，所以冰激凌的销量和犯罪率同时提高了。

哲学家努力尝试通过为他们所称的“背景因子”（混杂因子的另一种说法）设置限定条件来修复定义，并据此建构了表达式P（Y|X，K=k）>P（Y|K=k），其中K代表背景变量。事实上，如果我们把温度作为背景变量，那么这个表达式的确适用于冰激凌的例子。例如，如果我们只看温度为30℃的日子（K=30），我们就会发现冰激凌的销售和犯罪率之间不存在任何残留的关联。只有把30℃的日子和0℃的日子进行比较，我们才会产生概率提高的错觉。

对于“哪些变量要放入背景因子集合K中作为条件”这一问题，还没有一个哲学家能够给出一个令人信服的通用答案。原因显而易见：混杂也是一个因果概念，因此很难用概率来表示。

南希·卡特赖特打破了这一僵局，她利用因果要素丰富了我们关于背景语境的描述。她提出，我们应该将所有与结果有“因果关联”的因子都视为条件纳入考虑。

拯救概率提高这一概念的正确方法是借助do算子来定义：如果P（Y|do（X））>P（Y），那么我们就可以说X导致了Y。

哲学家的优势在于能够从激烈的科学辩论和数据处理方面的现实困扰中解脱出来。

是的，“因果幽灵”无处不在。箭头总是由因指向果，并且研究者与实践者常常能注意到，当他们反转了箭头之后，整个推断系统就变得无法控制了。但在很大程度上，他们认为这只是一种文化上的惯性思维，或者是某种旧思维模式的产物，并不涉及人类智能行为的核心层面。

贝叶斯网络适用于一个所有问题都被简化为概率或者（用本章的术语来说就是）变量间的关联程度的世界，它无法自动升级到因果关系之梯的第二层级或第三层级。

在此，我想说明的主要观点是：概率能将我们对静态世界的信念进行编码，而因果论则告诉我们，当世界被改变时，无论改变是通过干预还是通过想象实现的，概率是否会发生改变以及如何改变。

对单个金属球来说，向左或向右弹落看上去完全是随机的。然而，如果你往高尔顿板里倒入很多小球，一个惊人的规律就出现了：在底部堆积的小球的上边缘总是会形成一个近似钟形的曲线。

正如丹尼尔·卡尼曼在他的著作《思考，快与慢》中总结的：“成功=天赋+运气，巨大的成功=更多的天赋+更多的运气。”

后来，他又意识到一个更令人吃惊的事实：在进行代际比较时，向均值回归的时间顺序可以逆转。也就是说，子辈的父辈的遗传特征情况也会回归到均值。即儿子的身高若高于均值，则其父亲的身高很可能也高于均值，但往往父亲要比儿子矮（见图2.2）。在意识到这一点时，高尔顿不得不放弃了寻找向均值回归的因果解释的任何想法，因为子辈的身高显然不可能是父辈身高的因。

你可以根据父亲的身高预测儿子的身高，或者根据儿子的身高“预测”父亲的身高，这两种情况是完全对称的。这再次表明，对于向均值回归这一现象，因和果是没有区别的。

高尔顿无意间发现了一个重要事实：预测总是落在一条直线上，他称这条直线为回归线，它比椭圆的主轴（或对称轴）的斜率小（见图2.3）。事实上，这样的直线有两条，我们选择哪条线作为回归线取决于我们要预测哪个变量而将哪个变量作为证据。

高尔顿提出的相关性概念首次在不依赖于人的判断或解释的前提下以客观度量说明了两个变量是如何关联的。

极具讽刺意味的是，高尔顿尝试将《物种起源》的理论框架数学化的初衷最终导向了他对这部伟大著作的精髓的摒弃！

事实上，如果我们追踪梅花机中从一层落到下一层的某个小球，我们会看到，小球在下一层的位移继承了其沿路撞到的所有钉子带给它的变化的总和。

遗憾的是，他被自己漂亮但有缺陷的因果模型误导，继而发现了相关性的美，并从此开始相信科学不再需要因果关系了。

“辉格史观”（Whig history）就是一个针对此种做法的批判性术语，用于嘲弄事后诸葛亮式的历史写作风格——只关注成功的理论和实验，而对失败的实验和陷入僵局的理论发展几乎只字不提。

鼠子宫内存在的某种“发育因子”（developmental factors）导致了豚鼠某些特征的变异。我们现在已经知道赖特的这一假设是正确的。

没有因果假设，就不可能得出因果结论。

也许他在美国中西部地区的成长经历和他所念的那所名不见经传的大学激发了他的自立精神，并教会了他，最可靠的知识就是由自己亲手构建的知识。

贝叶斯分析的原型是这样的：先验判断+新的证据→经过修正的判断。例如，假设你抛掷10次硬币，发现其中有9次结果是正面朝上。那么此时你认为硬币抛掷是一个公平的游戏这一判断就可能会发生动摇，但你具体在多大程度上动摇了呢？一位正统的统计学家会说：“在没有任何额外证据的情况下，我倾向于认为这枚硬币掺有杂质，所以我敢打赌，下一次抛掷硬币时，硬币正面朝向的概率为9∶1。” 而一位贝叶斯统计学家会说：“等一下，我们还需要考虑一下我们对于这枚硬币的先验知识。”这枚硬币是从附近的杂货店买的，还是从一个名声不怎么样的赌徒那儿得来的？如果这只是一枚普通的硬币，那么大多数人是不会因为9次结果为正面朝上的巧合就发生动摇的。

贝叶斯统计为我们提供了一种将观察到的证据与我们已有的相关知识（或主观判断）结合起来以获得修正后的判断的客观方法，借由这种方法，我们就可以对下一次硬币抛掷结果的预测进行修正。

频率派无法忍受的正是贝叶斯学派允许观念以主观概率的形式“入侵”“纯洁”的统计学王国的做法。

随着数据量的增加，先验判断的影响会越来越小，乃至彻底消失，这就让我们最终得到的那个结论仍然是客观的。

即使数据量增加，因果信息中的主观成分也不一定会随着时间的推移而减少。绘制出两个不同的因果图的两个人可以分析相同的数据，但很可能永远不会得出相同的结论，无论数据有多“大”。

因果图就是一个贝叶斯网络，其中每个箭头都表示一个直接的因果关系，或者至少表明了存在某个因果关系的可能性。反过来，并非所有的贝叶斯网络都是因果关系网络，而在很多实际应用中这一点并不重要。

休谟的主要观点是，本质上不可靠的证据是不能推翻衍生于自然法则的诸如“人死不能复生”这样的命题的。

为什么前向概率（已知L求x的概率）比逆概率（已知x求L的概率）更容易估算？在这个例子中，这种不对称性来自L为因x为果这一事实。若我们观察到一个因，如鲍比向窗户扔球，则大多数人可以预测到果（球可能会打破窗户）。人类的认知就是在这个方向上运作的。但若给定了果（窗户破了）要求我们推断因，则我们就需要更多的信息才能进行推断（是哪个男孩扔球打破了窗户？窗户是被球打破的吗？）。

P（S|T）P（T）=P（T|S）P（S）　 这个看似简单的方程就是贝叶斯法则。如果仔细观察它所表达的内容，我们就能发现它提供了逆概率问题的一种通用解决方案。

我们还可以将贝叶斯法则看作一种方法，用以更新我们对某一特定假设的信念。理解这一点非常重要，因为人类对未来事件的信念大多取决于该事件或类似事件在过去发生的频率。

但没有人明确说过，信念可以等同于或应该等同于数据中的比例。

哲学层面的异议聚焦于将概率解释为一种信念度（degree of belief）的观点，我们在茶室例子中含蓄地使用了这种解释。

我们不仅应该把贝叶斯法则看作“条件概率”这一新概念的便捷定义，而且应该将其视作一个实证性的指称，其忠实地表达了“假设我知道”这句短语。

如果T是一个发生概率极低的神迹（“基督复活了”），而S是一个与之密切相关的假设（“基督是上帝之子”），则当我们知道T真实发生了之后，我们对S的信念度就会大幅提升。

证据T越出乎意料，即P（T）越小，人们就越应相信它的因S存在或发生。

从许多层面来说，贝叶斯法则都是对科学方法的提炼。教科书对科学方法的描述是这样的：（1）提出一个假设，（2）推断假设的可检验结果，（3）进行实验并收集证据，（4）更新对假设的信念。通常，教科书涉及的只是简单的正确和错误两种结果的检测和更新，证据要么证实了假设，要么驳斥了假设。但是生活和科学从来不会那么简单！所有的证据都包含一定程度的不确定性。贝叶斯法则告诉我们的正是如何在现实世界中执行步骤（4）。

硬性规则通常很难捕捉到真实生活中的知识。我们可能并没有意识到自己一直在应对例外情况和证据的不确定性。

在阅读鲁梅哈特的论文时，我更确信了这一点，即任何人工智能都必须建立在模拟我们所知道的人类神经信息处理过程的基础上，并且不确定性下的机器推理必须借助类似的信息传递的体系结构来构建。

在日常思考中，我们每个人都需要这种许可，否则我们会把很多时间花在寻找虚假的信号之上。

我相信，他们的本能一定来自某种心理表征，这种表征的形式很可能类似于因果图。

如果我们只选取著名演员的数据（换言之，我们现在只观察“名人=1”的数据），那么我们就会看到才华与美貌之间出现了负相关，这种负相关可以解释为：发现某位名人并不美貌这一事实，会使我们更相信他富有才华。

这种负相关有时被称为对撞偏倚或“辩解”效应（explain-away effect）。

贝叶斯网络的透明性使它有别于机器学习的其他模型，后者多倾向于制造高深莫测的“黑箱”。在贝叶斯网络中，你可以一个节点接一个节点地追踪，了解每一个新的证据是如何以及为何改变了整个网络中各个连接的信念的。

实际上，贝叶斯网络只不过是一张巨大的概率表的简洁表示形式。其中的箭头表示子节点的概率通过某个公式（条件概率表）与父节点的值相关联，并且此相关关系是充分的，即发现该子节点还有其他祖先节点不会改变这个公式。

而你很可能并不知道的是，对每个减肥成功的人而言，都有另外10个跟他条件相似的人也尝试了这种饮食法却没有成功。而显然，这些人是不可能出现在广告里的。

当一个变量同时影响到选择接受处理的对象以及试验结果时，混杂偏倚就产生了。有时混杂因子是已知的，另一些时候它们只是疑似存在，在分析中以“潜伏的第三变量”出现。

统计学家对于应该控制和不应该控制哪些变量感到非常困惑，所以默认的做法是控制他们所能测量的一切。当今时代的绝大多数研究都采用了这种做法。这的确是一种可轻松遵循的、便捷的、简单的程序，但它既浪费资源又错误百出。

混杂与数据或统计学无关，它是一个因果概念，属于因果关系之梯的第二层级。

在几乎所有的科学领域中，混杂都是一个历史悠久的问题，但直到最近，我们才认识到这个问题需要因果的而非统计的方法来解决。

一个明显的混杂因子可能是年龄：调查样本中的年轻男性可能更愿意进行积极的锻炼，那么其在12年追踪期内的死亡率自然相对较低。

自然就像一个精灵，她回答的正是我们提出的问题，但这个问题并不一定等同于我们真正打算问的那个问题。

我喜欢费舍尔·博克斯在上一段文字中给出的意象：自然就像一个精灵，她回答的正是我们提出的问题，但这个问题并不一定等同于我们真正打算问的那个问题。

科学难道不得不屈从于运气的反复无常？ 但是费舍尔意识到，得到对正确问题的不确定答案比得到对错误问题的高度确定的答案要好得多。如果你向自然精灵提出了一个错误的问题，那么你就永远不会得到你想知道的答案。如果你提出了正确的问题，那么偶尔得到一个错的答案就完全不成问题了。

因此，随机化实际上带来了两个好处。第一，它消除了混杂偏倚（它向大自然提出了正确的问题）。第二，它使研究者能够量化不确定性。

信息传递是双向的，既在因果方向传递，也在非因果方向传递。

事实上，非因果路径恰恰是混杂的根源。

福布斯发现，在原始数据中，吸烟与成人哮喘的关联很小且统计上不显著。在根据混杂因子进行统计调整后，这一关联变得更小、更不显著了。

驳斥吸烟致癌假说的一个最重要的科学主张是可能存在某些不可测量的因素，同时导致了人对尼古丁的渴求和人患肺癌。

毫无疑问，亚伯和雅克烟雾缭绕的辩论中有很多主题既不关乎烟草也不关乎癌症，而是关乎一个人畜无害的词——“导致”。

这些杰出的发现都蕴含着一个幸运的巧合——其原因与结果恰巧是一对一的关系。

吸烟与癌症之关系的辩论挑战了这种单一的因果关系概念。

对他们来说，潜伏的第三个因素可能才是我们所观察到的这种关联背后的原因所在。例如，可能存在一种吸烟基因既让人们更渴望吸烟，也使他们更有可能患上肺癌（也许是通过间接影响他们对于生活方式的选择达成的）。

1902年，香烟仅占美国烟草市场的2%，且烟草消费最普遍的标志在当时还是痰盂而不是烟灰缸。但是两股强大的力量一起改变了美国人的习惯：自动化和广告。

如果我们用图示表示出肺癌和烟草消费的比例关系（见图5.2），二者的关联就是不言而喻的。但时间序列数据对于因果关系的证明是一种非常糟糕的证据。1900年到1950年，许多其他的事情也发生了变化，它们同样有可能是罪魁祸首，比如道路铺设、含铅汽油尾气排放以及普遍的空气污染。

病例—对照设计也存在一些明显的弊端。首先，它是回顾性的，这意味着我们已知研究对象患有癌症，在此前提下我们要回顾过去找出原因。其次，它的概率逻辑也是反向的，这些数据告诉我们的是癌症患者是吸烟者的概率，而不是吸烟者患癌症的概率。对于那些想知道是否应该吸烟的人，吸烟者患癌症的概率才是他们真正关心的概率。

选择偏倚：已入院就医的癌症患者绝不是整个人口总体的代表性样本，甚至不能作为吸烟者总体的代表性样本。

回忆偏倚：虽然多尔和希尔确保了采访者不知道其采访对象是否患有癌症，但被采访者本人肯定知道他们自己是否患有癌症，而这一事实很可能会影响他们的回忆。

多尔和希尔意识到，如果病例—对照研究中的确存在隐藏的偏倚，那么仅仅靠重复研究肯定是无法消除偏倚的。

剂量—响应效应（dose-response effect）：如果物质A会导致生物反应B，则通常而言（但不是百分之百），更大剂量的A会导致更强的反应B。

如果吸烟者患肺癌的风险为常人的9倍，那么在吸烟者中，这种混杂因子存在的概率也需要至少比常人高出9倍，如此才能解释这种患病风险的差异。让我们思考一下这意味着什么：如果有11%的不吸烟者携带“吸烟基因”，那么就至少有99%的吸烟者一定携带吸烟基因。而如果有12%的不吸烟者碰巧携带这种基因，那么从数学的角度看，“吸烟基因”就不可能完全解释吸烟和癌症之间的相关。

在1954年3月的一次演讲中，菲利普·莫里斯公司的副总裁乔治·韦斯曼说：“如果我们认为或者获知我们销售的产品对消费者有害，我们一定会立即停业关店。”60年过去了，我们仍在等待菲利普·莫里斯践行这一诺言。

当科学家面对的是一个蓄意欺骗我们的对手时，其面临的挑战会有多大。

烟草公司的这些公开声明揭开了关于吸烟与癌症之关系这场争论中最令人痛心的一幕：烟草公司在烟草对健康的危害方面蓄意欺骗公众。

烟草公司夸大了它们能找到的任何一点科学争议，还成立了自己的烟草工业研究委员会，向科学家提供资金，委托他们研究关于癌症或烟草的问题，但永远不去涉及真正的核心问题。

时序关系也存在一些例外，例如此前提到的公鸡打鸣不会导致太阳升起，尽管公鸡打鸣总是出现在太阳升起之前。

儿童的鞋子码数与他们的阅读能力密切相关，

吸烟母亲的婴儿平均比不吸烟母亲的婴儿轻7盎司。然而，吸烟母亲的低出生体重婴儿的存活率要比不吸烟母亲的婴儿高。这就好像母亲的吸烟习惯真的具有某种保护作用一样。

对于某个低出生体重婴儿来说，其出生体重偏低有两种可能的解释：他可能有一个吸烟的母亲，或者，他可能受到了某个其他因素的影响。如果我们发现这个婴儿的母亲是吸烟者，则根据“辩解”效应，该因素就有力地解释了婴儿的低出生体重，从而减少了先天缺陷或其他因素存在的可能性。但是，如果婴儿的母亲不吸烟，那么我们就有更充分的理由说明，婴儿出生体重偏低的原因是遗传畸形，而根据这一结论，这名婴儿的预后诊断就会更糟。

谁能直面矛盾，谁就能触摸现实。 ——弗里德里希·迪伦马特（1962）

获得信息的方式和信息本身一样重要。

贝叶斯分析的一个普遍主题：任何通过了威胁其有效性的测试的假设，其可能性都会变得更大。威胁越大，幸存下来的假设的可能性就越大。

在我看来，要想真正解决一个悖论，我们应该首先解释为什么我们会把它看成一个悖论。

我们的大脑不擅长处理概率问题，但对因果问题则相当在行。而这种因果性的思维方式会导致系统性的概率错误，就像视错觉一样。

在一般人群中，大约有7.5%的人患有骨骼疾病，这一比例与患者是否患有呼吸系统疾病无关。但是，对于患有呼吸系统疾病的住院患者而言，其骨骼疾病的患病率会升至25%！萨克特称这种现象为“住院率偏倚”或“伯克森偏倚”。

以对撞因子为条件这一操作制造了“疾病1”和“疾病2”之间的伪相关。

无论是疾病1还是疾病2都没有严重到足以让患者必须住院的地步，但两者的结合会导致患者必须住院。在这种情况下，我们的预测是在住院病人这个总体中疾病1与疾病2高度相关。

我们在实际生活中似乎就是遵循着共因原则行事的，无论何时，只要观察到某种模式，我们就会去寻找一个因果解释。事实上，我们本能地渴望根据数据之外的某个稳定机制对观察结果做出解释。其中最令人满意的解释是直接因果关系：X导致Y。

在最纯粹、最本质的意义上，我们观察到的相关就是一种错觉，甚至可能是一种自欺欺人：我们选择哪些事件进入数据集同时忽略另一些事件的做法给我们自己带来了错觉。

可悲的事实是，没有魅力的人可能会和有魅力的人一样刻薄，但你永远意识不到这一点了，因为你永远不会约会既刻薄又没有魅力的人。

对撞的扭曲棱镜在日常生活中同样普遍存在。正如乔丹·埃伦伯格在《魔鬼数学》（How Not to Be Wrong）中提出的问题：你有没有注意到，在你约会的人当中，那些有魅力的人往往是混蛋？

你对约会对象的选择取决于两个因素：魅力和个性。你会冒险约会一个刻薄而有魅力的人，或者一个和蔼但缺乏魅力的人，你当然也会与既和蔼又有魅力的人约会，但你肯定不会与既刻薄又没有魅力的人约会。

辛普森悖论所引发的困惑是出于错误地将因果原则应用于解释统计比例。

辛普森逆转是一个纯粹的数字事实：在合并样本时，两个或多个不同的样本关于某一特定事件的相对频率出现反转。

较大的肾结石更可能需要通过开腹手术来摘取，并且有较大肾结石的病人本身的预后也更差。

•1996年发表的一篇观察性研究报告表明，对于摘除小型肾结石而言，开腹手术比内窥镜手术的成功率高，对于摘除较大的肾结石而言，开腹手术也有更高的成功率。然而就总体而言，开腹手术的成功率反而较低。

•在1995年发表的一份关于甲状腺疾病的研究报告中，数据显示吸烟者的存活率（76%）比不吸烟者的存活率（69%）更高，寿命平均多出20年。然而，在样本的7个年龄组中，有6个年龄组中不吸烟者的存活率更高，而第7个年龄组中二者的差异微乎其微。年龄显然是吸烟和存活率的混杂因子：吸烟者的平均年龄比不吸烟者小（很可能是因为年老的吸烟者已经死了）。根据年龄来分割数据，我们就可以得出正确的结论：吸烟对存活率有负面影响。

行动超越了言论的人，其言论将经久不衰。 ——拉比·哈宁拿·本·杜沙（公元1世纪）

无论是否经过统计调整，回归系数都只表示一种统计趋势，其自身并不能传递因果信息。

回归系数有时可以体现因果效应，有时则无法体现，而其中的差异无法仅依靠数据来说明。我们还需要具备另外两个条件才能赋予rYX.Z以因果合法性。第一个条件是，我们所绘制的相应的因果图应该能够合理地解释现实情况；第二个条件是，我们需要据其进行统计调整的变量Z应该满足后门标准。

早在20世纪50年代，焦油沉积的形成就被怀疑是肺癌发展的一个可能的中间阶段。

事实上，因果图的一个主要优势就是让假设变得透明，以供专家和决策者探讨和辩论。

对于一名科学工作者而言，其所能获得的最美妙的体验之一，可能就是坐在办公桌前，意识到自己终于即将弄清在现实世界中什么是可能的，什么是不可能的，尤其是当这个问题对整个人类社会而言非常重要，并且曾令那些试图解决该问题的前辈困扰许久的时候。

《犹太法典》中的一句话：“从我的老师那儿我学到了很多，从我的同事那儿我学到了更多，从我的学生那儿我学到的最多。”（《禁食篇》7a）。

事实上，能限制我们的只有我们自己的想象力。

“可惜我不能同时去涉足，我在那路口久久伫立……”

人类具有设想那个不存在的世界的能力，正是这一能力将我们与类人猿祖先以及地球上的其他生物区分开来。

遗憾的是，即使是世界上最具天赋的匹配者也不能将数据转化为潜在结果，连近似转化也不可能。

将中介物误认作混杂因子是因果推断中最致命的错误之一，很可能导致极为荒谬的错误结果。

著名的潜在结果研究者马歇尔·乔菲在2010年写道，人们之所以要做出可忽略性假设，通常是因为这类假设证实了使用现有的统计方法是合理的，而不是因为他们真的相信这类假设。

房子里有氧气很正常，但是我们很难说划火柴这一行为很正常。

最早的对照试验之一就是詹姆斯·林德船长对坏血病的研究，这项研究发表于1747年。

无知和傲慢——并且二者总是紧密结合在一起。

女生申请者被拒绝的人数更多，是因为她们倾向于申请更难被录取的系。

每个局部的公平就意味着总体的公平。

总效应=直接效应+间接效应

学生的成功不仅取决于你教给他们什么，还取决于你如何教他们。

引发肺癌的真正关键的因素是吸烟，

医生只能收集到那些活着被送到医院（而不是死在半途中）的士兵的数据。

他的这项研究没能成功，因为他无法收集到那些在到达医院之前就不幸丧命的士兵的数据。

就目前而言，我们仍然无法教会机器理解事情的前因后果。我们无法向电脑解释为什么转动气压计的刻度盘不会导致下雨。当一名行刑队的士兵改变想法，决定不开枪时，我们也无法教会机器理解这一情境并猜测接下来会发生什么。

科学家本应是最关心“为什么”的人，但由于他们长期束缚于统计学的工作氛围，其提问“为什么”的正当权利被剥夺了。

科学家还是会提出关于“为什么”的问题，但每当他们想用数学分析来解决这一问题时，他们就不得不将这一问题转化为一个关于关联的伪问题。

问问我们自己：我们真的离计算机或机器人能够理解因果对话的时代越来越近了吗？我们真的能制造出像三岁孩童那样富有想象力的人工智能吗？

某些领域存在着一种对数据的近乎宗教性的信仰。这些领域的研究者坚信，只要我们在数据挖掘方面拥有足够多的智慧和技巧，我们就可以通过数据本身找到这些问题的答案。然而，本书的读者已经明白，这种信仰是盲目的，很可能受到了对数据分析的大规模宣传炒作的误导。

当你看到一篇论文或一项研究是以模型盲的方式分析数据的时候，你就能确定其研究结果最多不过是对数据的总结或转换，而不可能包含对数据的合理解释。

有些人将数据挖掘看作研究的终结而不是第一步，

近年来，人工智能最显著的进步发生在一个被称为“深度学习”的领域，它采用的基本方法类似于卷积神经网络。这些网络不遵循概率规则，它们不以严谨或清晰的方式处理不确定性，也没有对其运行环境的明确表征。相反，这些网络的体系结构可以自行发展。在完成了一个对于新的网络的训练后，程序员就不再管它，也无从知晓它正在执行什么计算，或者它们为何有效。如果网络失灵，程序员也不知道应该如何修复它。

2017年，AlphaGo在战胜当时的围棋世界冠军柯洁之后正式“退役”。输给李世石的那一局，是它输给人类的唯一一局比赛。

这类程序或算法与我们对透明性的追求背道而驰。即使是AlphaGo的程序编写者也不能告诉我们为什么这个程序能把下围棋这个任务执行得这么好。

我们对深度学习的理解完全是经验主义的，没有任何保证。AlphaGo团队并没有在一开始就预测到，这个程序会在5年的时间内击败人类最好的围棋棋手。他们只是想试验一下，而AlphaGo出人意料地成功了。

我个人不喜欢模糊的系统，这就是我不研究此类系统的原因。

我对给出了出色表现的模糊系统感到不满意的原因——透明性才能确保有效的沟通。

今天的机器学习的确是一种有效方法，它让我们得以通过有限的样本估计总体的概率分布，但我们仍然需要在此基础上根据分布推测因果关系。

理解自己的意图，并用它作为因果推理的证据，具备这一能力就说明行为主体的智能已经达到了自我觉察的水平（但尚未达到自我意识的水平，如果这种分级是正确的话）。据我所知，目前还没有任何一个智能机器能达到这个水平。

如果机器人只会遵循存储在程序中的指令，那么它如何才能有自由意志呢？

到目前为止，我们只能在狭义的领域模拟人类思维，这些领域只涉及最原始的因果结构。在这些狭义的领域中，我们可以制造出比人类更出色的机器，这并不奇怪，因为这些领域关注的是计算机更擅长的事：计算。
