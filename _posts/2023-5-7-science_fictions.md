---
layout: post
title: Science Fictions
---
#### 科学本质上是一种社会事物，你必须让其他人——其他科学家——相信你的发现。
#### 让我们假设你想做一些研究。第一步是阅读科学文献。阅读与您的领域相关的期刊后，您可能会想到一个研究问题。资金绝不是确定的，任何科学家都会告诉你，这项工作中最艰苦的部分之一就是试图为他们最新的研究想法提供资金，而失败是非常普遍的。数据输入后，您通常会有一组数字，您或更具数学头脑的同事可以使用各种统计数据进行分析。论文准备好后，您就进入了科学期刊的世界，开始了发表竞争。
#### 一个大型科学家联盟，他们从三本顶级心理学期刊中选择了 100 项研究，并试图复制它们。该结果于 2015 年发表在《科学》杂志上，读起来令人苦涩：最终，只有 39% 的研究被判定成功复制。
#### 我们生活在这种不确定性中的原因之一是，几乎没有人进行复制研究。
#### 当机器学习研究人员分析了一组关于“推荐算法”的论文时，他们只能重现 18 项关于该主题的研究中的 7 项最近在著名的计算机科学会议上发表。
#### 在《自然》杂志网站上填写问卷的人将近 90% 的化学家表示，他们有过无法复制另一位研究人员的结果的经历；近 80% 的生物学家和近 70% 的物理学家、工程师和医学家持相同看法。
#### 在 2020 年初，获得诺贝尔奖的化学工程师弗朗西斯·阿诺德宣布她的团队从《科学》杂志上撤回一篇关于酶的论文，因为结果无法重复。
#### 印度和中国等国家对科学不端行为的更宽松的规定和更宽松的惩罚可能是导致它们产生更多潜在欺诈研究的原因。这再次强调，开展科学研究的社会环境可能对其质量产生严重影响。
#### 人们也有理由担心极权政府不会创造一个科学可以蓬勃发展的环境。科学需要透明度，需要方法重于结果，并且在意识形态上应该保持中立。这些不是在极权主义政权下蓬勃发展的概念。此外，获得尊重和权力职位的科学家很可能是那些取悦政权的人，例如，通过证明他们的文化宣传是真实的。因此，晋升的选择性压力不会优先考虑研究诚信。
#### p < 0.05 阈值意味着如果我们的假设是错误的（例如，我们的新药实际上不起作用），那么有 5% 的时间我们会得到假阳性结果——我们会声明我们的实验成功了，而事实上它并没有成功。如果我们进行五项（不相关的）测试，则至少有 23% 的机会出现误报；对于二十次测试，它是 64%。
#### p -hack过度拟合数据。
#### 一项针对中国实验室的更具体调查发现，高达 46% 的细胞系被错误识别。
#### 相关性不是因果关系。
#### 从 1974 年开始。“创新”、“有前途”和“稳健”等词的使用呈指数级增长； “独特”和“史无前例”（也许自相矛盾）变得更加普遍； '好评'稳步上升。“开创性”一直接近零，直到 1999 年左右，然后由于某种原因突然上升。
#### 83% 的报告抗抑郁和抗焦虑药物试验的论文未能讨论其研究设计的重要局限性。
#### 2009 年的一项审查表明，在中国医学期刊上发表的声称是随机对照试验的研究样本中，只有 7% 实际使用了随机化。
#### 在任何给定时间，通常都会有一个“新兴”领域受到最严重的炒作。
#### 在美国的一项研究中，据估计，科学家平均花费其总工作时间的 8% 和研究时间的 19% 来撰写资助申请——这两个数字在我看来都相当低。
#### 随着获得博士学位的人数增加，在大学工作中的职位空缺并没有跟上步伐。
#### 几乎所有学者都可以告诉你有一次匿名同行评审员恰好建议他们引用论文 X、Y 和 Z。
#### Ymkje Anna de Vries 和她的同事对 105 种不同的抗抑郁药进行了试验，这些试验已获得美国食品和药物管理局的批准。在这些试验中，阳性结果与阴性结果的比例恰好接近5：5。
#### 大学通常会保护科学造假者免受其行为后果的影响。
#### 一项关于心脏病预防的大规模试验研究清楚地说明了登记的影响。 2000 年引入预注册后发生的情况。突然之间只有几个积极的结果，其余研究报告了零效应，集中在零附近。要求注册前的试验成功率为 57%；之后，它暴跌至 8%。
#### 如何阅读科学论文：
#### 1.一切都光明正大吗？2.透明度如何？3.研究设计得好吗？4.样本有多大？5、影响有多大？6.推论是否恰当？7.有偏见吗？8.真的有几分可信？9.是否被复制？10.其他科学家对此有何看法？
<!-- more -->
我们按时写下了我们的结果，并将结果论文寄给了发表贝姆研究的同一本科学期刊，即《人格与社会心理学杂志》。几乎立刻，门就当着我们的面砰地关上了。编辑在几天内拒绝了这篇论文，并向我们解释说他们的政策是永远不会发表重复先前实验的研究，无论这些研究是否发现与原始结果相同的结果。

斯塔佩尔承认，他没有为他的研究收集数据，而是独自坐在办公室或厨房的桌子旁，直到深夜，将他想象的结果所需的数字输入电子表格，从头开始制作它们。

在许多方面，这就是科学的本质，也是它与其他了解世界的方式不同的地方：如果它不能复制，那么就很难将你所做的描述为科学。

科学本质上是一种社会事物，你必须让其他人——其他科学家——相信你的发现。

科学的社会本质也有其弱点。因为科学家们非常专注于说服他们的同行，这是他们通过同行评审并继续发表这些研究的方式，这对他们来说太容易了忽视科学的真正目标：让我们更接近真相。

让我们假设你想做一些科学。第一步是阅读科学文献。阅读与您的领域相关的期刊后，您可能会想到一个研究问题。资金绝不是确定的，任何科学家都会告诉你，这项工作中最艰苦的部分之一就是试图为他们最新的研究想法提供资金，而失败是非常普遍的。数据输入后，您通常会有一组数字，您或更具数学头脑的同事可以使用各种统计数据进行分析。论文准备好后，您就进入了科学期刊的世界，开始了发表竞争。

质量控制的第一步：由编辑将论文分类为符合期刊主题并在科学兴趣或质量方面具有潜力的论文，以及不值得再看的论文。对于确实让编辑看中的那部分文章，现在是同行评审的时刻了。编辑会找到两三个科学家，他们是你的专家研究领域并询问他们是否愿意评估您的手稿。

Kahneman后来承认他在过分强调启动效应的科学确定性方面犯了一个错误。 “我在那一章中提出的想法的实验证据比我写它时所相信的要弱得多，”他在《思考，快与慢》出版六年后评论道。 “这只是一个错误：我知道我需要知道的一切来缓和我的热情......但我没有考虑清楚。” 但损害已经造成：数百万人从一位诺贝尔奖获得者那里得知，他们“别无选择”，只能相信这些研究。

2019 年，研究员兼电影导演 Thibault Le Texier 发表了一篇题为“揭穿斯坦福监狱实验”的论文，其中他制作了前所未见的津巴多直接干预实验的录音笔录，让他的“看守”非常精确关于行为举止的说明——甚至提出使囚犯失去人性的具体方法，例如不让他们使用厕所。 显然，这种高度舞台管理的制作远非普通人被分配特定社会角色时发生的有机例子。尽管多年来受到了极大的关注，但斯坦福监狱实验的“结果”在科学上毫无意义。

一个大型科学家联盟，他们从三本顶级心理学期刊中选择了 100 项研究，并试图复制它们。该结果于 2015 年发表在《科学》杂志上，读起来令人苦涩：最终，只有 39% 的研究被判定成功复制。

在 2018 年，另一项努力试图复制发表在世界前两大综合科学期刊《自然》和《科学》上的 21 篇社会科学论文。 这一次，复制率为 62%。研究各种不同类型的心理现象的进一步合作发现了 77%、54% 和 38% 的比率。几乎所有的重复，即使是成功的，都发现最初的研究夸大了它们的效果。总的来说，复制危机似乎弹指一挥间，就把大约一半的心理学研究从地图上抹去了。

我们生活在这种不确定性中的原因之一是，几乎没有人进行复制研究。

在经济学中，所有发表的文章中只有可怜的 0.1% 是试图复制先前的结果；在心理学方面，这个数字要好一些，但仍远未达到理想水平，尝试复制率仅略高于 1%。 

当机器学习研究人员分析了一组关于“推荐算法”的论文时，他们只能重现 18 项关于该主题的研究中的 7 项最近在著名的计算机科学会议上发表。

生物技术公司 Amgen 的科学家们试图复制 53 项具有里程碑意义的“临床前”癌症研究，这些研究已发表在顶级科学期刊上。只有 6 次复制尝试（即仅 11%）成功。另一家公司拜耳的类似尝试的结果大约为 20%。

一项更全面的研究随机抽取了 268 篇生物医学论文（包括临床试验），发现除其中一篇外，其他论文均未报告其完整方案。这意味着，再一次，您甚至需要论文以外的其他详细信息来尝试复制该研究。另一项分析发现，54% 的生物医学研究甚至没有完全描述他们在实验中使用了何种动物、化学品或细胞。

常见的事实证明，治疗往往基于低质量的研究；公认的医学智慧没有坚实的证据基础，反而经常与新研究相矛盾。这种现象经常发生，以至于医学家 Vinay Prasad 和 Adam Cifu 给它起了个名字：“医学逆转”。

在《自然》杂志网站上填写问卷的人将近 90% 的化学家表示，他们有过无法复制另一位研究人员的结果的经历；近 80% 的生物学家和近 70% 的物理学家、工程师和医学家持相同看法。

Macchiarini 刚刚“历史上第一次”成功地将植入干细胞的完全合成的碳硅气管移植到一位癌症患者体内卡罗林斯卡医院。 同年 11 月，报告手术细节的科学论文发表，此时 Macchiarini 已对另一名卡罗林斯卡患者进行了类似手术。 该论文再次发表在《柳叶刀》杂志上，描述了移植成功的“确凿证据”。 作者遗漏了一个毁灭性的细节：相关患者已经死亡。

机构出于名誉动机而聘用和发表有魅力的科学家的愿望可能会导致对欺诈者的活动故意视而不见，有时甚至会延伸到保护他们免受其行为后果的影响。

图像复制一再出现，并且已成为近几十年来一些最突出的欺诈案件的核心特征。

Hwang 和 Obokata 的故事在一个明显的方面都很不寻常：造假文件的异常突出。这些是在《科学》和《自然》这两种世界领先期刊上发表的文章。如此显眼的造假通过了这些期刊的审查过程已经足够令人担忧了，但它们的声望意味着这些论文立即引起了全世界的关注——及其审查。如果这种欺诈发生在科学的最高水平，这表明在不太知名的期刊上还有更多的欺诈行为在雷达下飞行。

从根本上说，这是因为没有科学是真正精确的科学：数字是嘈杂的。每次你尝试测量任何东西时，你都会稍微偏离真实值，无论是一个国家的经济表现、世界上剩下的稀有猩猩的数量、亚原子粒子的速度，甚至是一些简单的东西比如某人有多高。

在 2020 年初，获得诺贝尔奖的化学工程师弗朗西斯·阿诺德宣布她的团队正在从《科学》杂志上撤回一篇关于酶的论文，因为结果无法重复。

在一般的撤稿中，无心之失仅占总数的 40% 或更少。大多数是由于某种形式的不道德行为，包括欺诈（约 20%）、重复发表和剽窃。

撤回论文的总体比例——大约每 10,000 篇已发表的研究中有 4 篇，即 0.04%。

图像复制更可能发生在一些国家而不是其他国家：印度和中国在有复制图像的论文数量中所占比例过高，而美国、英国、德国、日本和澳大利亚的代表人数不足。作者提出，这些差异是文化上的：印度和中国等国家对科学不端行为的更宽松的规定和更宽松的惩罚可能是导致它们产生更多潜在欺诈研究的原因。这再次强调，开展科学研究的社会环境可能对其质量产生严重影响。

人们也有理由担心极权政府不会创造一个科学可以蓬勃发展的环境。科学需要透明度，需要方法重于结果，并且在意识形态上应该保持中立。这些不是在极权主义政权下蓬勃发展的概念。此外，获得尊重和权力职位的科学家很可能是那些取悦政权的人，例如，通过证明他们的文化宣传是真实的。因此，晋升的选择性压力不会优先考虑研究诚信。 

在 2010 年代初对中国生物医学研究人员进行的一项调查中，参与者估计他们的同胞发表的所有生物医学文章中约有 40% 受到某种科学不端行为的影响； 71% 的受访者表示，中国当局“没有或很少关注”不当行为案件。

2014 年的一篇论文发现，后来因研究诚信办公室的不当行为而受到谴责的美国科学家，都是此前几年一直在为资金而苦苦挣扎的人。

如此多的欺诈行为设法渗透到文献中的一个原因是，一般来说，科学家们是开放的和信任的。

2015 年，研究人员跟进了欺诈性麻醉师 Scott Reuben 的案例，到 2009 年他有 20 篇论文被撤回（他现在在排行榜上排名第 27 位，撤回了 24 篇）。在随后的五年中，这些论文获得了 274 次引用，而在大约四分之一的案例中，引用的科学家似乎意识到他们已被撤回。这些僵尸论文仍在科学文献中蹒跚而行，几乎没有人注意到它们已经死了。

被撤回的论文仍然经常被引用，而不仅仅是受到批评，这一事实意味着许多科学研究都依赖于完全错误的信息。

一个直截了当但具有破坏性的原因：科学家根据他们的结果选择是否发表研究。

发表偏见。它也被称为“文件抽屉问题”，现在已不合时宜地被称为“文件抽屉问题”——因为据说科学家们将所有无效结果都藏在这里，不让世人看到。

p值的定义非常棘手。最近的一项审计发现，令人震惊的 89% 的入门心理学教科书样本中的定义是错误的。

Fisher 最初建议将“统计显着性”阈值设置为 0.05——这意味着我们对每次测试的假阳性错误的容忍度不应超过 5%。

统计显着性的 0.05 截止值鼓励研究人员认为低于它的结果不知何故是“真实的”，而高于它的结果则无可救药地“无效”。

样本量。在其他条件相同的情况下，大型研究因为包含更多数据，预计会更接近“真实”效果（整个人群的平均效果）。换句话说，大型研究对真实效果的最佳猜测往往比小型研究更准确。

对癌症研究的评论更糟：72% 没有包括发表偏倚检查。

p -hacking 有两种主要形式。其一，追求特定假设的科学家运行并重新运行并重新运行他们对实验的分析，每次都以略微不同的方式进行，直到机会最终赋予他们低于 0.05 的 p值。他们可以通过各种方式对这些即兴分析进行更改：删除特定数据点、重新计算特定子组内的数字（例如，先检查对男性的影响，然后再检查对女性的影响）、尝试不同类型的统计测试，或者保留在收集新数据时不打算停止，直到某些事情变得重要为止。 第二个选项涉及采用现有数据集，在不考虑特定假设的情况下对其运行大量临时统计测试，然后简单地报告碰巧使p值低于 0.05 的任何影响。后一种p -hacking 被称为 HARKing，即已知结果后的假设。 “德州神枪手”经常重复的类比很好地总结了这一点，他拿着左轮手枪，随机地用枪声扫过谷仓的一侧，然后大摇大摆地走过去，在碰巧靠近谷仓的几个弹孔周围画一个靶心彼此，声称那是他一直瞄准的地方。

这两种p -hacking都是同一个错误的实例，具有讽刺意味的是，这恰恰是p值被发明来避免的错误：利用随机机会。

p < 0.05 阈值意味着如果我们的假设是错误的（例如，我们的新药实际上不起作用），那么有 5% 的时间我们会得到假阳性结果——我们会声明我们的实验成功了，而事实上它并没有成功。如果我们进行五项（不相关的）测试，则至少有 23% 的机会出现误报；对于二十次测试，它是 64%。

基本见解：即使没有任何事情发生，您仍然会定期获得“显着”的p值，尤其是当您运行大量统计测试时。

2012 年，一项针对 2,000 多名心理学家的民意调查询问他们是否参与了一系列p -hacking 实践。 他们是否曾经收集过关于几个不同结果的数据但没有报告所有结果？大约 65% 的人说他们有。在查看结果后，他们是否从分析中排除了特定的数据点？ 40% 的人说是。大约 57% 的受访者表示，他们在进行分析后决定收集更多数据——并且可能发现这些数据并不令人满意。

37% 的经济学家表示，他们“在得到’他们的‘结果时停止了统计分析”——也就是说，每当p恰好低于 0.05 时，即使它可能是偶然的。

p -hack过度拟合数据。

生命受到威胁的领域也无法避免这种偏见。几代医学生都被正确地教导，双盲、随机、安慰剂对照试验是新疗法证据的黄金标准。如果做得好，这样的试验可以排除安慰剂效应、实施干预的医生的偏见、治疗以外的因素导致的虚假结果（所谓的“混杂”），以及困扰临床研究的许多其他问题。但即使是最严格控制的临床试验也不能排除结果出来后出现的偏差： 分析试验数据时的偏差。

从 2005 年开始，国际医学期刊编辑委员会认识到出版偏倚的巨大问题，规定所有人体临床试验在进行之前都应该公开注册——否则它们将不允许在大多数顶级医学期刊上发表。Ben Goldacre 的“COMPare Trials”项目对五个最具影响力的医学期刊上发表的所有临床试验进行了为期四个月的研究，试图将它们与注册相匹配。 在六十七项试验中，只有九项报告了他们所说的一切。在所有论文中，有 354 个结果在注册和发表之间消失了（可以安全地假设其中大多数的p值超过 0.05），而 357 个未注册的结果出现在期刊论文中。 类似的对麻醉研究注册的审计发现，92% 的试验至少改变了一个结果——而且，也许可以预见，这种改变往往是针对具有统计显着性结果的结果。

Reinhart 和 Rogoff 在他们的分析中使用的 Microsoft Excel 电子表格中存在一个错误：几个国家的债务被排除在方程式之外。 具体而言，该电子表格在其计算中忽略了澳大利亚、奥地利、比利时、加拿大和丹麦的债务。可怕的平庸的理由？错别字。当这个得到更正，以及对 Reinhart 和 Rogoff 所做的另外几个有争议的分析选择的修正，债务比率和增长之间的关系发生了巨大变化。 该文件称，高于 90% 的平均增长率为 -0.1%；修正后为+2.2%。

即使是来自科学文献的“经典”发现——那些你希望经过最严格检验的发现——也可能完全不可靠，数字和数据应该是最重要的部分，它们只是为一个引人注目的故事服务的门面装饰。

2006 年的一项研究发现，只有微不足道的 26% 的心理学家愿意根据电子邮件请求将他们的数据发送给其他研究人员，其他领域的数据也同样令人沮丧。您也不太可能能够访问较早的研究获得的数据。 

2017 年的一项分析搜索了使用已知被错误识别的细胞系进行研究的文献，发现了惊人的 32,755 篇论文使用了所谓的冒名顶替细胞，还有超过 500,000 篇论文引用了这些受污染的研究。（因为科学家研究的许多细胞系都是癌细胞，因此受到污染论文数量最多的研究领域无疑是肿瘤学。）

一项针对中国实验室的更具体调查发现，高达 46% 的细胞系被错误识别。

在使用受污染细胞发表的论文中，36% 来自美国。

事后看来，通读候选基因文献是一种超现实的体验：他们在我们现在知道完全错误的基础上建造了一座庞大的详细研究大厦。正如 Slate Star Codex 博客的 Scott Alexander 所说：“这不仅仅是一位从东方归来并声称那里有独角兽的探险家。探险家描述了独角兽的生命周期、独角兽吃什么、独角兽的所有不同亚种、独角兽的哪些肉块最好吃，以及独角兽和大脚怪之间摔跤比赛的详细描述。

相关性不是因果关系。

如果我们发现喝更多的咖啡与更高的智商相关（顺便说一句，确实如此），我们就不能得出“咖啡提高智商”的结论。 因果箭头可以很容易地指向相反的方向，更聪明会让你喝更多的咖啡。或者，第三个因素——例如来自更富裕的社会经济阶层，这可能会让你更健康，从而给你更高的智商，以及导致你喝更多的咖啡。

2017 年的一项研究发现，只有大约 50% 的媒体报道的健康研究最终得到元分析的证实（也就是说，50% 的研究被发现可以广泛复制）。

成长心态变化约占成绩变化的 1%。在学生中培养成长心态的努力，将接受心态训练的实验组与未接受心态训练的对照组进行比较，结果并没有好多少。

睡眠时间长短与死亡风险之间存在 U 形关系：每晚睡眠时间超过 8 小时的人寿命较短，就像那些只睡 5 小时或更短时间的人一样。

《我们为什么要睡觉》一本销量如此之高的书中大量误导性陈述应该让我们彻夜难眠。

我们刚刚讨论的书籍分别出自斯坦福大学、耶鲁大学和伯克利大学的教授之手。如果连一流的科学家都不介意夸大证据，其他人为什么要介意呢？

从 1974 年开始。“创新”、“有前途”和“稳健”等词的使用呈指数级增长； “独特”和“史无前例”（也许自相矛盾）变得更加普遍； '好评'稳步上升。“开创性”一直接近零，直到 1999 年左右，然后由于某种原因突然上升。

摘要中正面词语的使用增加了近九倍：1974 年只有 2% 的摘要有与 2014 年的 17.5% 相比，包含了这种自我表扬。

科学家更频繁地使用这种语言，因为这是让他们的结果吸引读者的好方法，也许更重要的是，吸引知名期刊的审稿人和编辑。最有魅力的期刊在他们的网站上声明他们想要具有“巨大潜在影响力”的论文（《自然》 ）； “在各自领域最具影响力”和“提供新颖且广泛重要的数据”（《科学》 ）；并且具有“不寻常的意义”（细胞）或“特别重要”（美国国家科学院院刊）。

在顶级期刊上发表的肥胖治疗试验中有 47% 在某种程度上是错误的。

83% 的报告抗抑郁和抗焦虑药物试验的论文未能讨论其研究设计的重要局限性。

2009 年的一项审查表明，在中国医学期刊上发表的声称是随机对照试验的研究样本中，只有 7% 实际使用了随机化。 

在任何给定时间，通常都会有一个“新兴”领域受到最严重的炒作。通常情况下，一些在知名期刊上发表的易于掌握的结果会被媒体报道，公众的兴趣会增强，而该领域的科学家会产生一种鲁莽，用粗心和夸大的言论助长炒作周期。然后大的主张在后来的实验中无法复制，狂热平息，正常的科学恢复。超级炒作的领域包括干细胞、遗传学、表观遗传学、机器学习和脑成像；在过去的几年里，“最受关注”奖的有力竞争者是对微生物组的研究——栖息在我们体内的数以百万计的微生物。

几乎没有令人信服的证据表明用不饱和脂肪代替饱和脂肪的好处。

事实上，某人饮食的任何给定方面都可能与其他方面相关，从而使影响分析复杂化：吃更多鸡蛋的人可能也吃更多的培根和香肠。

根据科学共识，没有什么比光速移动得更快。这是爱因斯坦狭义相对论的基础，迄今为止我们从物理学中得到的每一个结果都支持它。这就是 2011 年的观察结果OPERA 实验如此离奇。然后，当然，他们发现了错误。这是一个错误的连接：松动的光纤电缆导致低估了中微子所花费的时间。一旦正确插入，时间就会符合爱因斯坦的理论。

在所有科学领域，2013 年的快照发现当年发表了 240 万篇新论文。另一项涵盖整个科学史的分析表明，上升趋势正在加速：1650 年至 1750 年的年增长率为 0.5%，1750 年至 1940 年的年增长率为 2.4%，此后8%的增长率。后者的速度意味着整个科学文献的数量每九年就会翻一番。

自 1990 年代初以来，中国大学一直实行一项政策，即向科学家（至少是自然科学领域的科学家）支付现金奖励，以奖励他们在主流国际科学期刊上发表的每篇论文。同样的直接现金换出版计划的版本已被报道为土耳其和韩国的政府政策，以及其他国家的某些大学，包括卡塔尔，沙特阿拉伯阿拉伯、台湾、马来西亚、澳大利亚、意大利和英国。

在学术就业市场上，招聘和晋升决定在很大程度上取决于您的简历上发表了多少篇文章，以及发表在哪些期刊上。

在包括英国在内的许多国家，大学本身由政府根据其学术论文的声望进行排名，纳税人的钱也会相应地分配。 所有这些都是陈词滥调“不发表就灭亡”（publish-or-perish）的由来：不断地发表论文，并尽可能在最令人印象深刻的期刊上发表论文，否则你将永远无法在现代学术界竞争激烈的世界中生存。

进行科学研究的第一个必要步骤通常是获得资助，用于支付设备、材料、数据访问、参与者奖励和员工工资。这意味着科学家们需要不断地申请资助来维持他们的研究。同样，大学也承受着同样的压力。他们从他们的科学家设法赢得的任何赠款中抽取一部分，并用它来补贴教学、招聘、建筑维护等。出于这个原因，他们严重依赖他们的学者来带来现金。在美国的一项研究中，据估计，科学家平均花费其总工作时间的 8% 和研究时间的 19% 来撰写资助申请——这两个数字在我看来都相当低。 

永远寻求资金不仅仅是时间的消耗：它会导致大量的失败和失望。这个问题因所谓的马太效应而变得更加复杂：分配科学经费后，本已富有的人会变得更富有。 

一项法国研究发现，2013 年聘用的年轻进化生物学家发表的论文数量几乎是 2005 年聘用人员的两倍，这意味着聘用标准逐年上升。

随着获得博士学位的人数增加，在大学工作中的职位空缺并没有跟上步伐。

黑龙江大学高教授相当于 Status Quo 乐队的学术等价物，该乐队通过从 1970 年代开始对同一对基本摇滚歌曲进行无休止的小变奏而获得成功。它确实离查尔斯·达尔文很远。高参与了一个被称为“香肠切片”的过程：将一组科学结果（通常来自一项研究）作为一篇论文一起发表，然后将它们分成更小的子论文，每个子论文其中可以单独发布。

一项调查发现对抗抑郁药度洛西汀的研究进行了广泛的意大利腊肠切片。仅举众多例子中的一个，度洛西汀研究人员发表了一篇论文，研究了药物作用中的黑人-白人种族差异，另一篇研究了西班牙裔-白人的差异，尽管所有数据都来自相同的试验。

Potemkin 出版物由不道德的企业经营，这些企业试图利用科学家众所周知的对更多出版物的渴望。他们用垃圾邮件充斥收件箱，通常使用蹩脚的英语，恳求科学家提交他们的研究，并吹嘘他们的期刊接受文章的速度有多快。遗憾的是，许多缺乏经验、粗心或绝望的研究人员被诱骗在其中发表文章（当然，还要支付期刊要求“处理”文章的费用）。

最糟糕的掠夺性期刊几乎会发表任何内容，甚至是最明显的骗局。 2014 年，计算机科学家 Peter Vamplew 对掠夺性期刊《国际高级计算机技术杂志》源源不断的垃圾邮件感到非常恼火，以至于他提交了一篇题为“让我离开你他妈的邮件列表”的笑话文章。这篇论文完全由“让我离开你他妈的邮件列表”这句话组成，重复了八百多次（包括一个有用的流程图图，上面有方框和箭头，描绘了信息Get→me→off→Your→Fucking→Mail→ing→List） .该杂志将其评为“优秀”并接受出版。

在发表后的五年内，大约 12% 的医学研究论文和大约 30% 的自然科学和社会科学论文的引用次数为零。

增加引用次数的一种更有效的方法就是引用自己。一项分析发现，在论文发表后的前三年，自引约占所有引文的三分之一。

几乎所有学者都可以告诉你有一次匿名同行评审员恰好建议他们引用论文 X、Y 和 Z。

大多数期刊由 Elsevier 或 Springer 等营利性公司运营。

就像发表次数和h指数一样，影响因子也可以被故意玩弄。一旦科学家们开始通过自我引用、强制引用和其他可疑做法人为地夸大这些数字，它们就失去了衡量科学质量的意义。

Ymkje Anna de Vries 和她的同事对 105 种不同的抗抑郁药进行了试验，这些试验已获得美国食品和药物管理局的批准。在这些试验中，阳性结果与阴性结果的比例恰好接近5：5。

大学通常会保护科学造假者免受其行为后果的影响。在我们看过的著名案例中，保密的大坝最终破灭，骗子的名字——Diederik Stapel、Paolo Macchiarini、Woo-suk Hwang、Jan Hendrik Schön 和其他许多人——被曝光。但在许多较低级别的研究不端行为案例中，身份从未公开过。

在分析了所有这些组合之后，Orben 和 Przybylski 发现有一些分析显示屏幕时间有相当大的负面影响，有些根本没有影响，有些则显示屏幕时间时间实际上是有益的。他们取了平均值。这是负面的，但确实非常微弱，屏幕时间约占幸福感变化的 0.4%。从这个角度来看，它与人们发现的幸福感和经常吃土豆之间的相关性大致相同，但小于幸福感和戴眼镜之间的联系。

一项关于心脏病预防的大规模试验研究清楚地说明了登记的影响。 2000 年引入预注册后发生的情况。突然之间只有几个积极的结果，其余研究报告了零效应，集中在零附近。要求注册前的试验成功率为 57%；之后，它暴跌至 8%。

《科学》杂志在 2020 年进行的一项调查发现，超过 55% 的试验的结果向美国政府的试验登记处报告的时间较晚。可以说，这不是它应该的工作方式：只有遵循已注册的计划，预注册才有用。

对科学的信任从一个非常高的基线开始。 Wellcome Global Monitor 从世界各地收集有关人们的数据对科学和科学家的态度；在 2018 年的全球样本中，平均有 72% 的人表示对科学有中等或高度信任，澳大利亚和新西兰的这一比例高达 92%。不可否认，一些地区报告的信任度要低得多：例如，中非只有 48%，而南美洲只有 65%。

即使你读到对一项研究的看似毁灭性的批评，批评本身可能是错误的，批评的批评也可能是错误的。

如何阅读科学论文：

1.一切都光明正大吗？2.透明度如何？3.研究设计得好吗？4.样本有多大？5、影响有多大？6.推论是否恰当？7.有偏见吗？8.真的有几分可信？9.是否被复制？10.其他科学家对此有何看法？